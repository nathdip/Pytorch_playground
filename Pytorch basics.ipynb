{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Pytorch?\n",
    "\n",
    "Pytorch is a power numerical library that is native to Python just like numpy and scipy. The one advantage it has over numpy is that it can operate over GPUs when asked for unlike numpy. Pytorch has been built primarily to implement deep neural networks over both CPUs and GPUs. Let us look some of the basic blocks of Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.3748e+37  1.9896e+31\n",
      " 1.1520e-38  0.0000e+00\n",
      " 2.5662e+30  9.9234e+21\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see that one can randomly initialize a torch tensor in this case a tensor of size 3 x 2. Of course such an initialization is not particularly useful specially when we want to initialize weights of a neural network for example. Just like numpy, torch also as access to many types of random number generators and we can in principle initialize the weights of an untrained neural network using such a scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights =  torch.randn(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.1925  0.3731 -1.0291\n",
      "-0.0325  0.5206 -0.7136\n",
      "-0.7641  2.5335 -1.3800\n",
      "-0.2068  0.1668 -2.2258\n",
      "-0.8391 -0.9635 -1.4378\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch tensor weights have been initialized using the randn method that generates random numbers from a normal distribution. Let us initialize another torch tensor to play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.6304  0.0974  0.4601\n",
      " 0.7145  0.9756  0.7628\n",
      " 0.9100  0.1750  0.0988\n",
      " 0.9744  0.6793  0.6484\n",
      " 0.5958  0.6238  0.5687\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add two tensors we use torch.add method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = torch.add(weights, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.4379  0.4705 -0.5690\n",
      " 0.6819  1.4962  0.0492\n",
      " 0.1458  2.7085 -1.2811\n",
      " 0.7676  0.8461 -1.5774\n",
      "-0.2433 -0.3396 -0.8691\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also add the tensor in place. For e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4379  0.4705 -0.5690\n",
       " 0.6819  1.4962  0.0492\n",
       " 0.1458  2.7085 -1.2811\n",
       " 0.7676  0.8461 -1.5774\n",
       "-0.2433 -0.3396 -0.8691\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.__add__(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This another method to perform the addition operation. You use any operation in this and apply in this form to perform this operation. Let's us look at how to perform multiplication operations using tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [5 x 3], m2: [5 x 3] at d:\\pytorch\\pytorch\\torch\\lib\\th\\generic/THTensorMath.c:1416",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-89e4531e504d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim_tensor1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdim_tensor2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [5 x 3], m2: [5 x 3] at d:\\pytorch\\pytorch\\torch\\lib\\th\\generic/THTensorMath.c:1416"
     ]
    }
   ],
   "source": [
    "torch.matmul(y, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why the error above?\n",
    "As you can see there is a dimensional mismatch in the above scenario. We can fix this by transposing one of the tensors so that the multiplication operation is a valid one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.5414  2.5010 -5.4397\n",
       "-0.8481  0.4998 -3.4468\n",
       "-0.8002  0.3794 -3.4150\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(y.t(), weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the method t() on the matrix in order to transpose a tensor. To know the size of the tensor use the size method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to numpy you can extract individual components or block of data from the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0974\n",
       " 0.9756\n",
       " 0.1750\n",
       " 0.6793\n",
       " 0.6238\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.460060715675354"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.6793\n",
       " 0.6238\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[3:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of such a tensor is also a tensor, but possibly of a different size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion from numpy to torch tensor and vice versa\n",
    "Most of the real world data which you might be using will be most likely in the numpy format. This also means that the in order to use pytorch on this data you have to convert it into a torch tensor. This is very easy to do as we will demonstrate in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Conversion from numpy array to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_array = np.random.randn(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.25482475 -1.05668625  0.50470798 -1.46718752]\n",
      " [-1.26139207 -1.10446727  0.47014498  0.04560771]\n",
      " [ 0.29193466 -0.40821379 -0.50282283  0.77099609]\n",
      " [-1.13177407  0.97220356  0.66009802 -1.38028801]\n",
      " [-1.9907153   0.68522901 -0.12355705  0.43001804]]\n"
     ]
    }
   ],
   "source": [
    "print(n_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_tensor = torch.from_numpy(n_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2.2548 -1.0567  0.5047 -1.4672\n",
      "-1.2614 -1.1045  0.4701  0.0456\n",
      " 0.2919 -0.4082 -0.5028  0.7710\n",
      "-1.1318  0.9722  0.6601 -1.3803\n",
      "-1.9907  0.6852 -0.1236  0.4300\n",
      "[torch.DoubleTensor of size 5x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(n_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Conversion from torch tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_array = n_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.25482475 -1.05668625  0.50470798 -1.46718752]\n",
      " [-1.26139207 -1.10446727  0.47014498  0.04560771]\n",
      " [ 0.29193466 -0.40821379 -0.50282283  0.77099609]\n",
      " [-1.13177407  0.97220356  0.66009802 -1.38028801]\n",
      " [-1.9907153   0.68522901 -0.12355705  0.43001804]]\n"
     ]
    }
   ],
   "source": [
    "print(new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus it is very easy to switch between a torch tensor and numpy as well. In addition we can also move the computations to GPU using the cuda function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    n_tensor = n_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2.2548 -1.0567  0.5047 -1.4672\n",
      "-1.2614 -1.1045  0.4701  0.0456\n",
      " 0.2919 -0.4082 -0.5028  0.7710\n",
      "-1.1318  0.9722  0.6601 -1.3803\n",
      "-1.9907  0.6852 -0.1236  0.4300\n",
      "[torch.cuda.DoubleTensor of size 5x4 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(n_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us perform some computations using some torch.cuda tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(5, 5)\n",
    "y = torch.rand(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-2.3299 -1.6405 -2.4680 -1.1606 -1.8798\n",
       " 1.2381  1.1436  0.1950 -0.0786  1.1633\n",
       " 3.4173  2.7793  2.9334  1.3266  2.6512\n",
       "-1.1908 -1.2413 -0.4674 -0.2828 -0.2856\n",
       "-2.3846 -2.3926 -2.6581 -0.7883 -2.8752\n",
       "[torch.cuda.FloatTensor of size 5x5 (GPU 0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see that it is very simple and straight forward to move the computations to the GPU. In the next tutorial we will look more into more faetures of Pytorch. We will learn enough features of pytorch so that we are able to implement a linear regressor at the start and then move towards more complex features.\n",
    "\n",
    "#### Note: Pytorch supports CUDA computations only on graphic cards with compute capability > 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
